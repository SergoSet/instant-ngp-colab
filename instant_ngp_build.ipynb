{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/instant-ngp-colab/blob/main/instant_ngp_build.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fAjMk8jDvp5"
      },
      "source": [
        "# Instant-ngp \n",
        "\n",
        "This notebook aims to be a step-by-step guide to train NeRF models and rendering videos from them with nvidia's [instant-ngp](https://github.com/NVlabs/instant-ngp) software using:\n",
        " * **Colab** for the heavy lifting.\n",
        " * A low-resource **local computer** for the steps that require having a graphical user interface (GUI).\n",
        "\n",
        "It has been tested on a GTX 1050ti in the local machine and an assigned Tesla T4 in the remote one.\n",
        "\n",
        "Based on this [notebook](https://colab.research.google.com/drive/10TgQ4gyVejlHiinrmm5XOvQQmgVziK3i?usp=sharing) by [@myagues](https://github.com/NVlabs/instant-ngp/issues/6#issuecomment-1016397579), the main differences being the addition of steps 3 and 4 to ensure compatibility between the local machine and the models trained in the remote machine, of step 10 to render a video from the scene, and a more guided approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxsmRf03DFYe"
      },
      "source": [
        "## 1.Connect to a GPU runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjFWI3WDPBr"
      },
      "source": [
        "Connect your colab session to a GPU runtime and check that you have been assigned a GPU. It should have a minimum of 8GB of available memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJC-0GitoJEh",
        "outputId": "0af4179b-9dde-4df2-aaf4-fcbc10d4976c"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da9sDpM-DXps"
      },
      "source": [
        "## 2. Install dependencies and clone the instant-ngp repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKFsL8wSdQ8Q",
        "outputId": "0e16885c-9282-4c82-912c-465ec6dde54c"
      },
      "outputs": [],
      "source": [
        "!apt update && apt install build-essential git python3-dev python3-pip libopenexr-dev libxi-dev libglfw3-dev libglew-dev libomp-dev libxinerama-dev libxcursor-dev colmap ffmpeg jq\n",
        "!pip install --upgrade cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijgdl-TUcxnd",
        "outputId": "e413476f-5043-4723-8339-bf22988410cd"
      },
      "outputs": [],
      "source": [
        "!git clone --recursive https://github.com/nvlabs/instant-ngp\n",
        "%cd instant-ngp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF4CRM2-rqn1"
      },
      "source": [
        "## 3. Set compute capability\n",
        "Find the compute capability of the GPU in your **local** machine in the following link:\n",
        "https://developer.nvidia.com/cuda-gpus\n",
        "\n",
        "You need this to be able to open your trained models in `testbed` inside your local machine later on, so you can explore them or trace a camera path in order to generate a video from your scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf9H-wO0o1Ax",
        "outputId": "e6332360-f07d-487b-abda-9ce76ed379fc"
      },
      "outputs": [],
      "source": [
        "compute_capability = \"61\" #@param [50, 52, 60, 61, 70, 72, 75, 80, 86, 87]\n",
        "%env TCNN_CUDA_ARCHITECTURES=$compute_capability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6PLafxjtoc1"
      },
      "source": [
        "## 4. Set the right network configuration\n",
        "For compatibility between the model trained here and the local machine, a network with FP32 or FP16 is chosen.\n",
        "\n",
        "https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html#hardware-precision-matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZAbFtUqQkc",
        "outputId": "92cd4308-62ef-465f-d996-1ed301f1c4f4"
      },
      "outputs": [],
      "source": [
        "network_type = \"FullyFusedMLP\" if int(compute_capability) >= 70 else \"CutlassMLP\"\n",
        "print(f\"Using {network_type}\")\n",
        "%env NN_CONFIG_PATH = ./configs/nerf/base.json\n",
        "!jq '.network.otype = \"CutlassMLP\" | .rgb_network.otype = \"CutlassMLP\"' $NN_CONFIG_PATH | sponge $NN_CONFIG_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9XhY2souWum"
      },
      "source": [
        "## 5. Build the project and install python requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7E55zXYc1gD",
        "outputId": "904f6f13-36d9-47fa-c9c3-5475a62d67da"
      },
      "outputs": [],
      "source": [
        "!cmake . -B build -DNGP_BUILD_WITH_GUI=OFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpuhlQmJcDPJ",
        "outputId": "9e8d56a9-e9aa-4db1-c73d-0b213ee0a6be"
      },
      "outputs": [],
      "source": [
        "!cmake --build build --config RelWithDebInfo -j `nproc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRfrshaCdpY8",
        "outputId": "3e90ae80-0d15-490a-d17d-caa4d808af5a"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLYSiD05EnL"
      },
      "source": [
        "## 6. [LOCAL MACHINE] Run COLMAP on your scene\n",
        "COLMAP doesn't work on machines without a GUI.\n",
        "\n",
        "Go to your local machine and follow the [instructions](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md#preparing-new-nerf-datasets) to run COLMAP from a video or a set of images to generate camera positions from your scene.\n",
        "\n",
        "After this, you should have an images folder, with the images of your scene, and a `transforms.json` file with the camera information extracted by COLMAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQP4PAyru3KA"
      },
      "source": [
        "## 7. Upload your scene"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Tl_nNpzfPR"
      },
      "source": [
        "Mount your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-CfnpVUze1G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOx86Jz5xOQP"
      },
      "source": [
        "Then upload the `images` folder and the output of COLMAP, `transforms.json`, to your drive. The structure should be similar to the following:\n",
        "```\n",
        "/content/drive/MyDrive/nerf_scenes/\n",
        "└── fox\n",
        "    ├── images\n",
        "    │   ├── 00001.jpg\n",
        "    │   └── 00002.jpg\n",
        "    └── transforms.json\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNhWLCgH20-g"
      },
      "source": [
        "Enter the path to your scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayZ2gWkTz3sU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "scene_path = \"/content/drive/MyDrive/nerf_scenes/fox\" #@param {type:\"string\"}\n",
        "if not os.path.isdir(scene_path):\n",
        "  raise NotADirectoryError(scene_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPr9nJ-w2_0J"
      },
      "source": [
        "## 8. Train a model on your scene!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aijHZB0zJwWB",
        "outputId": "b947a4a1-e158-47a5-a4b9-a2e7d4db9290"
      },
      "outputs": [],
      "source": [
        "train_steps = 2000  #@param {type:\"integer\"}\n",
        "snapshot_path = os.path.join(scene_path, f\"{train_steps}.msgpack\")\n",
        "!python ./scripts/run.py --scene {scene_path} --mode nerf --n_steps {train_steps} --save_snapshot {snapshot_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWuAHgOw8M4s"
      },
      "source": [
        "## 9. [LOCAL MACHINE] Generate a camera path\n",
        "\n",
        "Congrats! You now have a trained nerf checkpoint. Now, in order to generate a video with it, you will need to open it in your local machine with `testbed` and generate a `base_cam.jon` file following these [instructions](https://github.com/NVlabs/instant-ngp#testbed-controls). Remember to launch with the `--no-train` argument so that it doesn't start to train on your PC. Setting up the cameras can make your GUI pretty laggy, you can try to play with the `--height` and `--width` parameters or cropping your scene with the `Crop aabb` options to optimize the performance.\n",
        "\n",
        "Example command:\n",
        "```\n",
        "./build/instant-ngp --scene data/nerf/fox --no-train --snapshot /data/nerf/fox/2000.msgpack\n",
        "```\n",
        "\n",
        "After you're done, **upload `base_cam.json` to the root folder of your scene.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5XVO_oi-riY"
      },
      "source": [
        "## 10. Render video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_2t4NHHAvn5"
      },
      "source": [
        "Make sure `base_cam.json` exists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04Yt6prm_FJI"
      },
      "outputs": [],
      "source": [
        "video_camera_path = os.path.join(scene_path, \"base_cam.json\")\n",
        "if not os.path.isfile(video_camera_path):\n",
        "  raise FileNotFoundError(video_camera_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFuUotyA0HV"
      },
      "source": [
        "Render the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3XJeTeF1yJE",
        "outputId": "e493bdd8-903e-4c8e-ab01-8c8baed8b5dc"
      },
      "outputs": [],
      "source": [
        "video_n_seconds = 5 #@param {type:\"integer\"}\n",
        "video_fps = 25 #@param {type:\"integer\"}\n",
        "width = 720 #@param {type:\"integer\"}\n",
        "height = 720 #@param {type:\"integer\"}\n",
        "output_video_path = os.path.join(scene_path, \"output_video.mp4\")\n",
        "\n",
        "!python scripts/run.py --mode nerf --scene {scene_path} --load_snapshot {snapshot_path} --video_camera_path {video_camera_path} --video_n_seconds 2 --video_fps 25 --width 720 --height 720 --video_output {output_video_path}\n",
        "print(f\"Generated video saved to:\\n{output_video_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "instant_ngp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "80f0ca567e8a8332be8d0227e77114b80c729e82298f4777b19db59a6217bb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
